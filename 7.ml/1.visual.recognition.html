<html>
<head>

<title>Visual Recognition</title>

<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">

<style>
body {
  align-items: center;
  display: flex;
  flex-direction: column;
  justify-content: center;
  margin: 0;
  padding: 0;
}

canvas {
  border: solid 1px lightgrey;
}

img {
  left: 0;
  position: absolute;
  top: 0;
  visibility: hidden;
}

p {
  color: black;
  font-family: 'Roboto', sans-serif;  
  font-size: 24px;
  height: 70px;
  line-height: 70px;
  margin: 0;
  padding: 0;
  text-align: center;
}
</style>

</head>
<body>

<!-- Display contents -->
<canvas width="640" height="480"></canvas>

<!-- Display results -->
<p>&nbsp;</p>

<!-- Dropped image -->
<img>

<!-- Watson speech library -->
<script src="../lib/watson-speech.min.js"></script>

<script>
class Machine {
  constructor() {
    // Canvas references
    // Used for encoding image for CSS background
    this.canvas = document.querySelector( 'canvas' );
    this.canvas.addEventListener( 'dragover', ( evt ) => this.doDragOver( evt ) );
    this.canvas.addEventListener( 'drop', ( evt ) => this.doDragDrop( evt ) );    
    this.context = this.canvas.getContext( '2d' );    

    // Display text of results
    this.output = document.querySelector( 'p' );        

    // Place to load the image
    this.sample = document.querySelector( 'img' );
    this.sample.addEventListener( 'load', ( evt ) => this.doImageLoad( evt ) );

    // Prepare to read file contents
    this.io = new FileReader();
    this.io.addEventListener( 'load', ( evt ) => this.doFileLoad( evt ) );    

    // Store Watson authorization token
    this.token = null;

    // Get Watson authorization token
    fetch( Machine.WATSON_TOKEN )
    .then( ( result ) => { return result.json(); } )
    .then( ( data ) => {
      this.token = data.body;
    } );        
  }

  draw() {
    // Calculate proportions
    // Sizing and placement
    let aspect = this.canvas.clientWidth / this.sample.clientWidth;
    let height = Math.round( this.sample.clientHeight * aspect );
    let left = 0;
    let top = Math.round( ( this.canvas.clientHeight - height ) / 2 );
    let width = this.canvas.clientWidth;

    if( this.sample.clientHeight >= this.sample.clientWidth ) {
      aspect = this.canvas.clientHeight / this.sample.clientHeight;
      width = Math.round( this.sample.clientWidth * aspect );
      top = 0;      
      left = Math.round( ( this.canvas.clientWidth - width ) / 2 );      
      height = this.canvas.clientHeight;
    }

    // Draw image to canvas
    this.context.clearRect( 0, 0, this.canvas.clientWidth, this.canvas.clientHeight );
    this.context.drawImage( this.sample, left, top, width, height );
  }

  doDragDrop( evt ) {
    // Item dropped
    // Prevent browser default (opening)
    // Read content of the file
    evt.preventDefault();
    this.io.readAsDataURL( evt.dataTransfer.files[0] );

    // Build multipart form
    // Include file reference
    let form = new FormData();
    form.append( 'file', evt.dataTransfer.files[0] );

    // Upload to Watson Visual Recognition
    fetch( Machine.RECOGNITION, {
      method: 'POST',
      body: form
    } )
    .then( ( result ) => { return result.json(); } )
    .then( ( json ) => { 
      // Build output
      let primary = json.images[0].classifiers[0].classes[0].class;
      let modifier = 'a';

      if( primary.charAt( 0 ) === 'a' || primary.charAt( 0 ) === 'o' ) {
        modifier = 'an';
      }

      let phrase = `This looks like ${modifier} ${primary}.`;

      // Display output
      this.output.innerHTML = phrase;
      
      // Have Watson speak the results
      WatsonSpeech.TextToSpeech.synthesize( {
        text: phrase,
        token: this.token
      } );

      // Debug
      console.log( json );      
    } );
  }

  doDragOver( evt ) {
    // Item dragged
    // Prevent browser default (opening)
    evt.preventDefault();
  }

  doFileLoad( evt ) {
    // File contents have been read
    // Place contents into image element
    this.sample.src = this.io.result;
  }

  doImageLoad( evt ) {
    // Image element has loaded
    // Draw onto canvas
    this.draw();
  }
}

Machine.RECOGNITION = 'https://openwhisk.ng.bluemix.net/api/v1/web/krhoyt%40us.ibm.com_dev/watson/visual.recognition';
Machine.WATSON_TOKEN = 'https://openwhisk.ng.bluemix.net/api/v1/web/krhoyt%40us.ibm.com_dev/watson/tts.token.json';

let app = new Machine();
</script>

</body>
</html>
